{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib as plt\n",
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "DEVICE = get_default_device()\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_to_device(dataset, device = None):\n",
    "    tensor_list_x, tensor_list_y = [], []\n",
    "\n",
    "    for x, y in dataset:\n",
    "        tensor_list_x.append(x)\n",
    "        tensor_list_y.append(y)\n",
    "    \n",
    "    X = torch.stack(tensor_list_x)\n",
    "    Y = torch.tensor(tensor_list_y)\n",
    "\n",
    "    if DEVICE is not None:\n",
    "        X = X.to(DEVICE)\n",
    "        Y = Y.to(DEVICE)\n",
    "    \n",
    "    return torch.utils.data.TensorDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dl(batch_size_train = 256, batch_size_valid = 1024, device = None):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    data_train = torchvision.datasets.MNIST('./mnist', train = True, download = True, transform = transform)\n",
    "    data_train = switch_to_device(data_train, device)\n",
    "    data_train, data_valid = torch.utils.data.random_split(data_train, [55000, 5000])\n",
    "\n",
    "    data_test = torchvision.datasets.MNIST('./mnist', train = False, download = True, transform = transform)\n",
    "    data_test = switch_to_device(data_test, device)\n",
    "\n",
    "    train_dl = DataLoader(data_train, batch_size=batch_size_train, shuffle=True)\n",
    "    valid_dl = DataLoader(data_valid, batch_size=batch_size_valid, shuffle=False)\n",
    "    test_dl = DataLoader(data_test, batch_size=batch_size_valid, shuffle=False)\n",
    "\n",
    "    return train_dl, valid_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possibility_normalize(possi, non_zero_perc, slimness):\n",
    "    mean = torch.mean(possi)\n",
    "    std = torch.std(possi)\n",
    "    new_possi = ((possi - mean)/std*non_zero_perc*slimness) + non_zero_perc\n",
    "    new_possi = torch.clip(new_possi, 0, 1)\n",
    "    return new_possi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_generation(possi):\n",
    "    non_zero = torch.bernoulli(possi)\n",
    "    possi_ = non_zero/2\n",
    "    neg_pos = torch.bernoulli(possi_)\n",
    "    res = non_zero - 2*neg_pos\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization(x, q_bits):\n",
    "    q_max = 2 ** q_bits - 1\n",
    "    x_max = torch.max(x)\n",
    "    x_min = torch.min(x)\n",
    "    q_x = q_max*(x - x_min)/(x_max - x_min)\n",
    "    q_x = torch.round(q_x)\n",
    "    return q_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_f_multiplication(q_a, q_w, b_a, b_w):\n",
    "    term_1 = 2*(torch.matmul(q_a, q_w))/((2 ** b_a - 1)*(2 ** b_w - 1))\n",
    "    term_2 = torch.matmul(q_a, torch.ones(q_w.shape)) / (2 ** b_a - 1)\n",
    "    return term_1 - term_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    @torch.no_grad()\n",
    "    def __init__(self, qa_flag = True, qa_bits = 2):\n",
    "        self.qa_flag = qa_flag\n",
    "        self.qa_bits = qa_bits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input):\n",
    "        if self.qa_flag:\n",
    "            q_input = quantization(input, self.qa_bits)\n",
    "            res = (torch.abs(q_input) + q_input) / 2.0\n",
    "        else:\n",
    "            res = (torch.abs(input) + input) / 2.0\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_CrossEntropy():\n",
    "    @torch.no_grad()\n",
    "    def __init__(self, qa_flag, qo_flag, qa_bits, qo_bits):\n",
    "        self.qa_flag = qa_flag\n",
    "        self.qo_flag = qo_flag\n",
    "        self.qa_bits = qa_bits\n",
    "        self.qo_bits = qo_bits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input, labels):\n",
    "        if self.qa_flag:\n",
    "            input = quantization(input, self.qa_bits)\n",
    "\n",
    "        exp_z = torch.exp(input)\n",
    "        sum_exp_z = torch.sum(exp_z, dim = 1).reshape(input.shape[0], 1)\n",
    "        softmax_z = exp_z/sum_exp_z\n",
    "\n",
    "        if self.qo_flag:\n",
    "            softmax_z = quantization(softmax_z, self.qo_bits)\n",
    "        loss = torch.sum(-(labels*torch.log(softmax_z))) / input.shape[0]\n",
    "        \n",
    "        return loss\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLinear:\n",
    "    @torch.no_grad()\n",
    "    def __init__(self, input_num, output_num, qa_flag = True, qa_bits = 2, qw_bits = 2, qb_bits = 2, device = None):\n",
    "        if device is None:\n",
    "            print(\"Must have device\")\n",
    "            return\n",
    "        self.device = device\n",
    "        self.input_num, self.output_num = input_num, output_num\n",
    "        self.qa_bits, self.qw_bits, self.qb_bits = qa_bits, qw_bits, qb_bits\n",
    "        self.weights = torch.randint(0, 2**self.qw_bits, (self.input_num, self.output_num)).to(device)\n",
    "        self.bias = torch.randint(0, 2**self.qb_bits, (1, self.output_num)).to(device)\n",
    "        self.weights = self.weights.float()\n",
    "        self.bias = self.bias.float()\n",
    "        self.w_u = torch.zeros(self.input_num, self.output_num).to(device)\n",
    "        self.b_u = torch.zeros(1, self.output_num).to(device)\n",
    "        self.w_pickflag = torch.zeros(self.input_num, self.output_num).to(device)\n",
    "        self.b_pickflag = torch.zeros(1, self.output_num).to(device)\n",
    "        self.w_p = torch.full((self.input_num, self.output_num), 1000.).to(device)\n",
    "        self.b_p = torch.full((1, self.output_num), 1000.).to(device)\n",
    "        self.qa_flag = qa_flag\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, input):\n",
    "        self.w_u = torch.zeros(self.input_num, self.output_num).to(self.device)\n",
    "        self.b_u = torch.zeros(1, self.output_num).to(self.device)\n",
    "        self.w_p = torch.full((self.input_num, self.output_num), 1000.).to(self.device)\n",
    "        self.b_p = torch.full((1, self.output_num), 1000.).to(self.device)\n",
    "        self.w_pickflag = torch.zeros(self.input_num, self.output_num).to(self.device)\n",
    "        self.b_pickflag = torch.zeros(1, self.output_num).to(self.device)\n",
    "        \n",
    "        if self.qa_flag:\n",
    "            q_input = quantization(input, self.qa_bits)\n",
    "            res = torch.matmul(q_input, self.weights) + self.bias\n",
    "        else:\n",
    "            res = torch.matmul(input, self.weights) + self.bias\n",
    "\n",
    "        return res\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def random_search(self, input, non_zero_percent):\n",
    "        if non_zero_percent>0.5:\n",
    "            slimness = 1-non_zero_percent\n",
    "        else:\n",
    "            slimness = non_zero_percent\n",
    "\n",
    "        temp_wp = possibility_normalize(self.w_p, non_zero_perc=non_zero_percent, slimness=slimness)\n",
    "        temp_bp = possibility_normalize(self.b_p, non_zero_perc=non_zero_percent, slimness=slimness)\n",
    "        self.delta_matrix_w = delta_generation(temp_wp)\n",
    "        self.delta_matrix_b = delta_generation(temp_bp)\n",
    "\n",
    "        temp_weights = torch.clip(self.weights + self.delta_matrix_w, 0, 2**(self.qw_bits) - 1)\n",
    "        temp_bias = torch.clip(self.bias + self.delta_matrix_b, 0, 2**(self.qb_bits) - 1)\n",
    "\n",
    "        self.delta_matrix_w = temp_weights - self.weights\n",
    "        self.delta_matrix_b = temp_bias - self.bias\n",
    "\n",
    "        self.w_pickflag = (self.w_pickflag + torch.abs(self.delta_matrix_w)) > 0\n",
    "        self.b_pickflag = (self.b_pickflag + torch.abs(self.delta_matrix_b)) > 0\n",
    "\n",
    "        if self.qa_flag:\n",
    "            q_input = quantization(input, self.qa_bits)\n",
    "            res = torch.matmul(q_input, temp_weights) + temp_bias\n",
    "        else:\n",
    "            res = torch.matmul(input, temp_weights) + temp_bias\n",
    "\n",
    "        return res\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def mid_update(self, delta_loss):\n",
    "        self.w_u = self.w_u + (delta_loss * self.delta_matrix_w)\n",
    "        self.b_u = self.b_u + (delta_loss * self.delta_matrix_b)\n",
    "\n",
    "        self.w_p = torch.mul(self.w_pickflag, self.w_p)/2 + torch.abs(delta_loss) * torch.abs(self.delta_matrix_w)/(torch.ones(self.w_pickflag.shape).to(self.device) + self.w_pickflag)\n",
    "        self.w_b = torch.mul(self.b_pickflag, self.b_p)/2 + torch.abs(delta_loss) * torch.abs(self.delta_matrix_b)/(torch.ones(self.b_pickflag.shape).to(self.device) + self.b_pickflag)\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def final_update(self, total_delta_loss, c):\n",
    "        plus_matrix_w = torch.zeros(self.weights.shape).to(self.device)\n",
    "        minus_matrix_w = torch.zeros(self.weights.shape).to(self.device)\n",
    "        plus_matrix_w[self.w_u >= (c*total_delta_loss)] = 1\n",
    "        minus_matrix_w[self.w_u <= -(c*total_delta_loss)] = -1\n",
    "        self.weights = self.weights + plus_matrix_w + minus_matrix_w\n",
    "\n",
    "        plus_matrix_b = torch.zeros(self.bias.shape).to(self.device)\n",
    "        minus_matrix_b = torch.zeros(self.bias.shape).to(self.device)\n",
    "        plus_matrix_b[self.b_u >= (c*total_delta_loss)] = 1\n",
    "        minus_matrix_b[self.b_u <= -(c*total_delta_loss)] = -1\n",
    "        self.bias = self.bias + plus_matrix_b + minus_matrix_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_BNN():\n",
    "    def __init__(self, device = None):\n",
    "        if device is None:\n",
    "            print(\"Must have device\")\n",
    "            return\n",
    "        else:\n",
    "            self.device = device\n",
    "        self.fc_1 = QLinear(input_num=28*28, output_num=1024, qa_flag=False, qa_bits=2, qw_bits=2, qb_bits=2, device = device)\n",
    "        self.Relu_1 = Relu(qa_flag=True, qa_bits=2)\n",
    "        self.fc_2 = QLinear(input_num=1024, output_num=1024, qa_flag=True, qa_bits=2, qw_bits=2, qb_bits=2, device = device)\n",
    "        self.Relu_2 = Relu(qa_flag=True, qa_bits=2)\n",
    "        self.fc_3 = QLinear(input_num=1024, output_num=10, qa_flag=True, qa_bits=2, qw_bits=2, qb_bits=2, device = device)\n",
    "        self.CrossEntropy = Softmax_CrossEntropy(qa_flag=False, qa_bits=0, qo_flag=False, qo_bits=0)\n",
    "        self.output = None\n",
    "        self.loss_base = None\n",
    "        self.total_delta_loss = 0\n",
    "    \n",
    "    def forward(self, input, labels, update_itr = 0):\n",
    "        self.total_delta_loss = 0\n",
    "        self.input = torch.reshape(input, (input.shape[0], 28*28))\n",
    "        output = self.fc_1.forward(self.input)\n",
    "        output = self.Relu_1.forward(output)\n",
    "        output = self.fc_2.forward(output)\n",
    "        output = self.Relu_2.forward(output)\n",
    "        output = self.fc_3.forward(output)\n",
    "        self.output = output\n",
    "        self.loss_base = self.CrossEntropy.forward(output, labels)\n",
    "\n",
    "        for i in range(update_itr):\n",
    "            output = self.fc_1.random_search(self.input, non_zero_percent=0.3)\n",
    "            output = self.Relu_1.forward(output)\n",
    "            output = self.fc_2.random_search(output, non_zero_percent=0.3)\n",
    "            output = self.Relu_2.forward(output)\n",
    "            output = self.fc_3.random_search(output, non_zero_percent=0.3)\n",
    "            loss = self.CrossEntropy.forward(output, labels)\n",
    "            delta_loss = self.loss_base - loss\n",
    "            self.total_delta_loss = self.total_delta_loss + torch.abs(delta_loss)\n",
    "            self.fc_1.mid_update(delta_loss)\n",
    "            self.fc_2.mid_update(delta_loss)\n",
    "            self.fc_3.mid_update(delta_loss)\n",
    "        \n",
    "\n",
    "    def update(self):\n",
    "        self.fc_1.final_update(self.total_delta_loss, 0.2)\n",
    "        self.fc_2.final_update(self.total_delta_loss, 0.2)\n",
    "        self.fc_3.final_update(self.total_delta_loss, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(stats):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (7, 3), dpi = 110)\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "\n",
    "    ax1.set_title(\"ERM loss\")\n",
    "    ax2.set_title(\"Valid Acc\")\n",
    "\n",
    "    ax1.setxlabel(\"iterations\")\n",
    "    ax2.setxlabel(\"iterations\")\n",
    "\n",
    "    itrs = [x[0] for x in stats['train-loss']]\n",
    "    loss = [x[1] for x in stats['train-loss']]\n",
    "    ax1.plot(itrs, loss)\n",
    "\n",
    "    itrs = [x[0] for x in stats['valid-acc']]\n",
    "    acc = [x[1] for x in stats['valid-acc']]\n",
    "    ax2.plot(itrs, acc)\n",
    "\n",
    "    ax1.set_ylim(0.0, 4.05)\n",
    "    ax2.set_ylim(0.0, 1.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_acc(model, dl, device = DEVICE):\n",
    "    acc = []\n",
    "\n",
    "    for X, y in dl:\n",
    "        one_hot_y = torch.zeros(X.shape[0], 10).to(device)\n",
    "        one_hot_y[[i for i in range(X.shap[0])], [k.item() for k in y]] = 1\n",
    "        model.forward(X, one_hot_y)\n",
    "        acc.append(torch.argmax(model.output, dim = 1) == y)\n",
    "\n",
    "    acc = torch.cat(acc)\n",
    "    acc = torch.sum(acc)/len(acc)\n",
    "\n",
    "    return acc.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, train_dl, valid_dl, test_dl, max_epochs=20, device=DEVICE):\n",
    "    itr = -1\n",
    "    stats = {'train-loss' : [], 'valid-acc' : []}\n",
    "    for epoch in range(max_epochs):\n",
    "        for X, y in train_dl:\n",
    "            itr += 1\n",
    "            one_hot_y = torch.zeros(X.shape[0], 10).to(device)\n",
    "            one_hot_y[[i for i in range(X.shape[0])], [k.item() for k in y]] = 1\n",
    "            model.forward(X, one_hot_y, 10)\n",
    "            model.update()\n",
    "            stats['train-loss'].append((itr, model.loss_base.item()))\n",
    "\n",
    "            if itr != 0 and itr % 20 == 0:\n",
    "                valid_acc = get_acc(model, valid_dl, device = device)\n",
    "                stats['valid-acc'].append((itr, valid_acc))\n",
    "                s = f\"{epoch}:{itr} [train] loss:{model.loss_base.item():.3f}, [valid] acc:{valid_acc:.3f}\"\n",
    "                print(s)\n",
    "    \n",
    "    test_acc = get_acc(model, test_dl, device=device)\n",
    "    print(f\"[test] acc:{test_acc:.3f}\")\n",
    "    return stats\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 20\n",
    "train_batch = 256\n",
    "valid_batch = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e88c3b044653>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_mnist_dl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP_BNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-7867e6c22322>\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(model, train_dl, valid_dl, test_dl, max_epochs, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mone_hot_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mone_hot_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train-loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-3c8223d40231>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, labels, update_itr)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mdelta_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_base\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_delta_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_delta_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmid_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmid_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmid_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-01ebdb6fa827>\u001b[0m in \u001b[0;36mmid_update\u001b[1;34m(self, delta_loss)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_u\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdelta_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_matrix_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_pickflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_loss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_matrix_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_pickflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_pickflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_pickflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_loss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_matrix_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_pickflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_pickflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl, test_dl = get_mnist_dl(batch_size_train=train_batch, batch_size_valid=valid_batch, device = DEVICE)\n",
    "model = MLP_BNN(device=DEVICE)\n",
    "stats = run_experiment(model, train_dl, valid_dl, test_dl, max_epochs=max_epochs, device = DEVICE)\n",
    "print_stats(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
