{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cpu')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "DEVICE = get_default_device()\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_to_device(dataset, device = None):\n",
    "    tensor_list_x, tensor_list_y = [], []\n",
    "\n",
    "    for x, y in dataset:\n",
    "        tensor_list_x.append(x)\n",
    "        tensor_list_y.append(y)\n",
    "    \n",
    "    X = torch.stack(tensor_list_x)\n",
    "    Y = torch.tensor(tensor_list_y)\n",
    "\n",
    "    if DEVICE is not None:\n",
    "        X = X.to(DEVICE)\n",
    "        Y = Y.to(DEVICE)\n",
    "    \n",
    "    return torch.utils.data.TensorDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dl(batch_size_train = 256, batch_size_valid = 1024, device = None):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    data_train = torchvision.datasets.MNIST('./mnist', train = True, download = True, transform = transform)\n",
    "    data_train = switch_to_device(data_train, device)\n",
    "    data_train, data_valid = torch.utils.data.random_split(data_train, [55000, 5000])\n",
    "\n",
    "    data_test = torchvision.datasets.MNIST('./mnist', train = False, download = True, transform = transform)\n",
    "    data_test = switch_to_device(data_test, device)\n",
    "\n",
    "    train_dl = DataLoader(data_train, batch_size=batch_size_train, shuffle=True)\n",
    "    valid_dl = DataLoader(data_valid, batch_size=batch_size_valid, shuffle=False)\n",
    "    test_dl = DataLoader(data_test, batch_size=batch_size_valid, shuffle=False)\n",
    "\n",
    "    return train_dl, valid_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmtric_quantization(x, q_bits):\n",
    "    q_max = 2**q_bits - 1\n",
    "    x_max = torch.max(x)\n",
    "    x_min = torch.min(x)\n",
    "    max = torch.max(torch.tensor([torch.abs(x_max), torch.abs(x_min)]))\n",
    "    q_x = x * (q_max/(2*max))\n",
    "    q_x = torch.floor(q_x)\n",
    "    return q_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmtric_quantizer():\n",
    "    def __init__(self, q_bits):\n",
    "        self.q_bits = q_bits\n",
    "\n",
    "    def forward(self, x):\n",
    "        q_max = 2**self.q_bits - 1\n",
    "        x_max = torch.max(x)\n",
    "        x_min = torch.min(x)\n",
    "        max = torch.max(torch.tensor([torch.abs(x_max), torch.abs(x_min)]))\n",
    "        q_x = x * (q_max/(2*max))\n",
    "        q_x = torch.floor(q_x)\n",
    "        self.coef = q_max/(2*max)\n",
    "        return q_x\n",
    "    \n",
    "    def backward(self, next_grad):\n",
    "        return next_grad*self.coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmtric_quantization(x, q_bits):\n",
    "    q_max = 2**q_bits - 1\n",
    "    x_max = torch.max(x)\n",
    "    x_min = torch.min(x)\n",
    "    q_x = (x - x_min) * (q_max/(x_max - x_min))\n",
    "    q_x = torch.round(q_x)\n",
    "    q_x = q_x - torch.round(torch.tensor(q_max/2))\n",
    "    return q_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Asymmtric_quantizer():\n",
    "    def __init__(self, q_bits):\n",
    "        self.q_bits = q_bits\n",
    "\n",
    "    def forward(self, x):\n",
    "        q_max = 2**self.q_bits - 1\n",
    "        x_max = torch.max(x)\n",
    "        x_min = torch.min(x)\n",
    "        q_x = (x - x_min) * (q_max/(x_max - x_min))\n",
    "        q_x = torch.round(q_x)\n",
    "        q_x = q_x - torch.round(torch.tensor(q_max/2))\n",
    "        self.coef = q_max/(x_max - x_min)\n",
    "        return q_x\n",
    "    \n",
    "    def backward(self, next_grad):\n",
    "        return next_grad*self.coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLinear:\n",
    "    @torch.no_grad()\n",
    "    def __init__(self, input_num, output_num, qa_flag = True, qw_flag = True, qb_flag = True, qa_bits = 2, qw_bits = 2, qb_bits = 2, device = None):\n",
    "        if device is None:\n",
    "            print(\"Must have device\")\n",
    "            return\n",
    "        self.device = device\n",
    "        self.input_num, self.output_num = input_num, output_num\n",
    "        self.qa_flag, self.qw_flag, self.qb_flag = qa_flag, qw_flag, qb_flag\n",
    "        self.qa_bits, self.qw_bits, self.qb_bits = qa_bits, qw_bits, qb_bits\n",
    "\n",
    "        if qa_flag:\n",
    "            self.a_quantizer = Asymmtric_quantizer(self.qa_bits)\n",
    "\n",
    "        self.fp_weights = torch.normal(0, 0.1, size = (self.input_num, self.output_num)).to(device)\n",
    "        if qw_flag:\n",
    "            self.w_quantizer = Symmtric_quantizer(self.qw_bits)\n",
    "            #self.q_weights = symmtric_quantization(self.fp_weights, qw_bits)\n",
    "            self.q_weights = self.w_quantizer.forward(self.fp_weights)\n",
    "        \n",
    "        self.fp_bias = torch.normal(0, 0.1, size = (1, self.output_num)).to(device)\n",
    "        if qb_flag:\n",
    "            self.b_quantizer = Symmtric_quantizer(self.qb_bits)\n",
    "            #self.q_bias = symmtric_quantization(self.fp_bias, qb_bits)\n",
    "            self.q_bias = self.b_quantizer.forward(self.fp_bias)\n",
    "\n",
    "        self.w_grad = None\n",
    "        self.b_grad = None\n",
    "        self.input_grad = None\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "\n",
    "        if self.qa_flag:\n",
    "            #self.input = asymmtric_quantization(self.input, self.qa_bits)\n",
    "            self.input = self.a_quantizer.forward(self.input)\n",
    "\n",
    "        if self.qw_flag:\n",
    "            self.use_weights = self.q_weights\n",
    "        else:\n",
    "            self.use_weights = self.fp_weights\n",
    "\n",
    "        if self.qb_flag:\n",
    "            self.use_bias = self.q_bias\n",
    "        else:\n",
    "            self.use_bias = self.fp_bias\n",
    "\n",
    "        self.output = torch.matmul(self.input, self.use_weights) + self.use_bias\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def backward(self, next_grad):\n",
    "        self.w_grad = torch.matmul(self.input.T, next_grad)\n",
    "        if self.qw_flag:\n",
    "            self.w_grad = self.w_quantizer.backward(self.w_grad)\n",
    "        \n",
    "        self.b_grad = torch.sum(next_grad, dim = 0)\n",
    "        if self.qb_flag:\n",
    "            self.b_grad = self.b_quantizer.backward(self.b_grad)\n",
    "        \n",
    "        self.input_grad = torch.matmul(next_grad, self.use_weights.T)\n",
    "        if self.qa_flag:\n",
    "            self.input_grad = self.a_quantizer.backward(self.input_grad)\n",
    "\n",
    "        return self.input_grad\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def update(self, lr):\n",
    "        self.fp_weights = self.fp_weights - lr*self.w_grad\n",
    "        if self.qw_flag:\n",
    "            #self.q_weights = symmtric_quantization(self.fp_weights, self.qw_bits)\n",
    "            self.q_weights = self.w_quantizer.forward(self.fp_weights)\n",
    "        self.fp_bias = self.fp_bias - lr*self.b_grad\n",
    "        if self.qb_flag:\n",
    "            #self.q_bias = symmtric_quantization(self.fp_bias, self.qb_bits)\n",
    "            self.q_bias = self.b_quantizer.forward(self.fp_bias)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    @torch.no_grad()\n",
    "    def __init__(self, qa_flag, qa_bits):\n",
    "        self.qa_flag = qa_flag\n",
    "        self.qa_bits = qa_bits\n",
    "        if self.qa_flag:\n",
    "            self.a_quantizer = Asymmtric_quantizer(qa_bits)\n",
    "        self.input_grad = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        if self.qa_flag:\n",
    "            #self.input = asymmtric_quantization(input, self.qa_bits)\n",
    "            self.input = self.a_quantizer.forward(self.input)\n",
    "        self.output = (torch.abs(self.input) + self.input) / 2.0\n",
    "        return self.output\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def backward(self, next_grad):\n",
    "        self.input_grad = next_grad.clone()\n",
    "        self.input_grad[self.output <= 0] = 0\n",
    "        if self.qa_flag:\n",
    "            self.input_grad = self.a_quantizer.backward(self.input_grad)\n",
    "        return self.input_grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_CrossEntropy():\n",
    "    @torch.no_grad()\n",
    "    def __init__(self, qa_flag, qa_bits):\n",
    "        self.qa_flag = qa_flag\n",
    "        self.qa_bits = qa_bits\n",
    "        if self.qa_flag:\n",
    "            self.a_quantizer = Asymmtric_quantizer(qa_bits)\n",
    "        self.input_grad = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input, labels):\n",
    "        self.labels = labels\n",
    "        self.input = input\n",
    "        if self.qa_flag:\n",
    "            #self.input = asymmtric_quantization(self.input, self.qa_bits)\n",
    "            self.input = self.a_quantizer.forward(self.input)\n",
    "\n",
    "        exp_z = torch.exp(self.input)\n",
    "        sum_exp_z = torch.sum(exp_z, dim = 1).reshape(self.input.shape[0], 1)\n",
    "        self.softmax_z = exp_z/sum_exp_z\n",
    "        #print(self.softmax_z)\n",
    "        loss = torch.sum(-(labels*torch.log(self.softmax_z))) / self.input.shape[0]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def backward(self):\n",
    "        self.input_grad = self.softmax_z - self.labels\n",
    "        if self.qa_flag:\n",
    "            self.input_grad = self.a_quantizer.backward(self.input_grad)\n",
    "        return self.input_grad/self.labels.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import nextafter\n",
    "\n",
    "\n",
    "class Quantized_backprop_BNN():\n",
    "    def __init__(self, lr = 0.1, device = None):\n",
    "        if device is None:\n",
    "            print(\"Must have device\")\n",
    "            return\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "\n",
    "        self.fc_1 = QLinear(input_num=28*28, output_num=1024, qa_flag=False, qw_flag=False, qb_flag=False, qa_bits=8, qw_bits=8, qb_bits=8, device = self.device)\n",
    "        self.Relu_1 = Relu(qa_flag=False, qa_bits=8)\n",
    "        self.fc_2 = QLinear(input_num=1024, output_num=1024, qa_flag=True, qw_flag=True, qb_flag=True, qa_bits=4, qw_bits=4, qb_bits=4, device = self.device)\n",
    "        self.Relu_2 = Relu(qa_flag=True, qa_bits=4)\n",
    "        self.fc_3 = QLinear(input_num=1024, output_num=1024, qa_flag=True, qw_flag=True, qb_flag=True, qa_bits=4, qw_bits=4, qb_bits=4, device = self.device)\n",
    "        self.Relu_3 = Relu(qa_flag=True, qa_bits=4)\n",
    "        self.fc_4 = QLinear(input_num=1024, output_num=10, qa_flag=False, qw_flag=False, qb_flag=False, qa_bits=8, qw_bits=8, qb_bits=8, device = self.device)\n",
    "        self.Softmax_CrossEntropy = Softmax_CrossEntropy(qa_flag=False, qa_bits=8)\n",
    "        self.output = None\n",
    "        self.loss = None\n",
    "\n",
    "    def forward(self, input, labels):\n",
    "        self.input = torch.reshape(input, (input.shape[0], 28*28))\n",
    "        output = self.fc_1.forward(self.input)\n",
    "        output = self.Relu_1.forward(output)\n",
    "        output = self.fc_2.forward(output)\n",
    "        output = self.Relu_2.forward(output)\n",
    "        output = self.fc_3.forward(output)\n",
    "        output = self.Relu_3.forward(output)\n",
    "        output = self.fc_4.forward(output)\n",
    "        self.output = output\n",
    "        self.loss = self.Softmax_CrossEntropy.forward(output, labels)\n",
    "\n",
    "    def backward(self):\n",
    "        next_grad = self.Softmax_CrossEntropy.backward()\n",
    "        next_grad = self.fc_4.backward(next_grad)\n",
    "        next_grad = self.Relu_3.backward(next_grad)\n",
    "        next_grad = self.fc_3.backward(next_grad)\n",
    "        next_grad = self.Relu_2.backward(next_grad)\n",
    "        next_grad = self.fc_2.backward(next_grad)\n",
    "        next_grad = self.Relu_1.backward(next_grad)\n",
    "        next_grad = self.fc_1.backward(next_grad)\n",
    "\n",
    "    def update(self):\n",
    "        self.fc_1.update(self.lr)\n",
    "        self.fc_2.update(self.lr)\n",
    "        self.fc_3.update(self.lr)\n",
    "        self.fc_4.update(self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(stats):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (7, 3), dpi = 110)\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "\n",
    "    ax1.set_title(\"ERM loss\")\n",
    "    ax2.set_title(\"Valid Acc\")\n",
    "\n",
    "    ax1.set_xlabel(\"iterations\")\n",
    "    ax2.set_xlabel(\"iterations\")\n",
    "\n",
    "    itrs = [x[0] for x in stats['train-loss']]\n",
    "    loss = [x[1] for x in stats['train-loss']]\n",
    "    ax1.plot(itrs, loss)\n",
    "\n",
    "    itrs = [x[0] for x in stats['valid-acc']]\n",
    "    acc = [x[1] for x in stats['valid-acc']]\n",
    "    ax2.plot(itrs, acc)\n",
    "\n",
    "    ax1.set_ylim(0.0, 4.05)\n",
    "    ax2.set_ylim(0.0, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_acc(model, dl, device = DEVICE):\n",
    "    acc = []\n",
    "\n",
    "    for X, y in dl:\n",
    "        one_hot_y = torch.zeros(X.shape[0], 10).to(device)\n",
    "        one_hot_y[[i for i in range(X.shape[0])], [k.item() for k in y]] = 1\n",
    "        model.forward(X, one_hot_y)\n",
    "        acc.append(torch.argmax(model.output, dim = 1) == y)\n",
    "\n",
    "    acc = torch.cat(acc)\n",
    "    acc = torch.sum(acc)/len(acc)\n",
    "\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, train_dl, valid_dl, test_dl, max_epochs = 20, device = DEVICE):\n",
    "    itr = -1\n",
    "    stats = {'train-loss' : [], 'valid-acc' : []}\n",
    "    for epoch in range(max_epochs):\n",
    "        for X, y in train_dl:\n",
    "            itr += 1\n",
    "            one_hot_y = torch.zeros(X.shape[0], 10).to(device)\n",
    "            one_hot_y[[i for i in range(X.shape[0])], [k.item() for k in y]] = 1\n",
    "            model.forward(X, one_hot_y)\n",
    "            #print(\"Now is the iteration :\", itr)\n",
    "            '''\n",
    "            print(model.output)\n",
    "            '''\n",
    "            model.backward()\n",
    "            model.update()\n",
    "            stats['train-loss'].append((itr, model.loss.item()))\n",
    "\n",
    "            if itr != 0 and itr % 20 == 0:\n",
    "                valid_acc = get_acc(model, valid_dl, device = device)\n",
    "                stats['valid-acc'].append((itr, valid_acc))\n",
    "                s = f\"{epoch}:{itr} [train] loss:{model.loss.item():.3f}, [valid] acc:{valid_acc:.3f}\"\n",
    "                print(s)\n",
    "    \n",
    "    test_acc = get_acc(model, test_dl, device=device)\n",
    "    print(f\"[test] acc:{test_acc:.3f}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 50\n",
    "train_batch = 256\n",
    "valid_batch = 1024\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:20 [train] loss:2.892, [valid] acc:0.107\n",
      "0:40 [train] loss:2.671, [valid] acc:0.134\n",
      "0:60 [train] loss:2.501, [valid] acc:0.164\n",
      "0:80 [train] loss:2.356, [valid] acc:0.194\n",
      "0:100 [train] loss:2.232, [valid] acc:0.228\n",
      "0:120 [train] loss:2.119, [valid] acc:0.267\n",
      "0:140 [train] loss:2.019, [valid] acc:0.299\n",
      "0:160 [train] loss:1.927, [valid] acc:0.329\n",
      "0:180 [train] loss:1.845, [valid] acc:0.361\n",
      "0:200 [train] loss:1.770, [valid] acc:0.392\n",
      "1:220 [train] loss:1.700, [valid] acc:0.420\n",
      "1:240 [train] loss:1.634, [valid] acc:0.447\n",
      "1:260 [train] loss:1.576, [valid] acc:0.467\n",
      "1:280 [train] loss:1.521, [valid] acc:0.491\n",
      "1:300 [train] loss:1.471, [valid] acc:0.509\n",
      "1:320 [train] loss:1.425, [valid] acc:0.527\n",
      "1:340 [train] loss:1.382, [valid] acc:0.542\n",
      "1:360 [train] loss:1.342, [valid] acc:0.557\n",
      "1:380 [train] loss:1.304, [valid] acc:0.569\n",
      "1:400 [train] loss:1.270, [valid] acc:0.578\n",
      "1:420 [train] loss:1.238, [valid] acc:0.588\n",
      "2:440 [train] loss:1.208, [valid] acc:0.601\n",
      "2:460 [train] loss:1.180, [valid] acc:0.613\n",
      "2:480 [train] loss:1.153, [valid] acc:0.623\n",
      "2:500 [train] loss:1.128, [valid] acc:0.633\n",
      "2:520 [train] loss:1.105, [valid] acc:0.642\n",
      "2:540 [train] loss:1.084, [valid] acc:0.652\n",
      "2:560 [train] loss:1.062, [valid] acc:0.659\n",
      "2:580 [train] loss:1.043, [valid] acc:0.665\n",
      "2:600 [train] loss:1.024, [valid] acc:0.674\n",
      "2:620 [train] loss:1.006, [valid] acc:0.680\n",
      "2:640 [train] loss:0.989, [valid] acc:0.685\n",
      "3:660 [train] loss:0.973, [valid] acc:0.692\n",
      "3:680 [train] loss:0.958, [valid] acc:0.698\n",
      "3:700 [train] loss:0.945, [valid] acc:0.700\n",
      "3:720 [train] loss:0.930, [valid] acc:0.705\n",
      "3:740 [train] loss:0.917, [valid] acc:0.710\n",
      "3:760 [train] loss:0.904, [valid] acc:0.716\n",
      "3:780 [train] loss:0.892, [valid] acc:0.721\n",
      "3:800 [train] loss:0.880, [valid] acc:0.723\n",
      "3:820 [train] loss:0.869, [valid] acc:0.728\n",
      "3:840 [train] loss:0.859, [valid] acc:0.731\n",
      "4:860 [train] loss:0.848, [valid] acc:0.736\n",
      "4:880 [train] loss:0.838, [valid] acc:0.737\n",
      "4:900 [train] loss:0.829, [valid] acc:0.741\n",
      "4:920 [train] loss:0.820, [valid] acc:0.745\n",
      "4:940 [train] loss:0.812, [valid] acc:0.746\n",
      "4:960 [train] loss:0.803, [valid] acc:0.751\n",
      "4:980 [train] loss:0.795, [valid] acc:0.752\n",
      "4:1000 [train] loss:0.788, [valid] acc:0.755\n",
      "4:1020 [train] loss:0.780, [valid] acc:0.757\n",
      "4:1040 [train] loss:0.773, [valid] acc:0.759\n",
      "4:1060 [train] loss:0.766, [valid] acc:0.762\n",
      "5:1080 [train] loss:0.759, [valid] acc:0.763\n",
      "5:1100 [train] loss:0.752, [valid] acc:0.765\n",
      "5:1120 [train] loss:0.746, [valid] acc:0.768\n",
      "5:1140 [train] loss:0.740, [valid] acc:0.769\n",
      "5:1160 [train] loss:0.734, [valid] acc:0.770\n",
      "5:1180 [train] loss:0.728, [valid] acc:0.772\n",
      "5:1200 [train] loss:0.722, [valid] acc:0.773\n",
      "5:1220 [train] loss:0.716, [valid] acc:0.776\n",
      "5:1240 [train] loss:0.711, [valid] acc:0.777\n",
      "5:1260 [train] loss:0.706, [valid] acc:0.779\n",
      "5:1280 [train] loss:0.701, [valid] acc:0.783\n",
      "6:1300 [train] loss:0.695, [valid] acc:0.784\n",
      "6:1320 [train] loss:0.690, [valid] acc:0.786\n",
      "6:1340 [train] loss:0.686, [valid] acc:0.788\n",
      "6:1360 [train] loss:0.682, [valid] acc:0.791\n",
      "6:1380 [train] loss:0.678, [valid] acc:0.792\n",
      "6:1400 [train] loss:0.673, [valid] acc:0.794\n",
      "6:1420 [train] loss:0.669, [valid] acc:0.795\n",
      "6:1440 [train] loss:0.664, [valid] acc:0.796\n",
      "6:1460 [train] loss:0.660, [valid] acc:0.798\n",
      "6:1480 [train] loss:0.657, [valid] acc:0.799\n",
      "6:1500 [train] loss:0.653, [valid] acc:0.801\n",
      "7:1520 [train] loss:0.649, [valid] acc:0.803\n",
      "7:1540 [train] loss:0.646, [valid] acc:0.803\n",
      "7:1560 [train] loss:0.642, [valid] acc:0.804\n",
      "7:1580 [train] loss:0.638, [valid] acc:0.805\n",
      "7:1600 [train] loss:0.635, [valid] acc:0.806\n",
      "7:1620 [train] loss:0.631, [valid] acc:0.806\n",
      "7:1640 [train] loss:0.628, [valid] acc:0.808\n",
      "7:1660 [train] loss:0.625, [valid] acc:0.809\n",
      "7:1680 [train] loss:0.621, [valid] acc:0.811\n",
      "7:1700 [train] loss:0.618, [valid] acc:0.812\n",
      "8:1720 [train] loss:0.615, [valid] acc:0.814\n",
      "8:1740 [train] loss:0.612, [valid] acc:0.815\n",
      "8:1760 [train] loss:0.608, [valid] acc:0.816\n",
      "8:1780 [train] loss:0.605, [valid] acc:0.817\n",
      "8:1800 [train] loss:0.603, [valid] acc:0.816\n",
      "8:1820 [train] loss:0.601, [valid] acc:0.817\n",
      "8:1840 [train] loss:0.598, [valid] acc:0.818\n",
      "8:1860 [train] loss:0.596, [valid] acc:0.819\n",
      "8:1880 [train] loss:0.593, [valid] acc:0.820\n",
      "8:1900 [train] loss:0.590, [valid] acc:0.821\n",
      "8:1920 [train] loss:0.588, [valid] acc:0.822\n",
      "9:1940 [train] loss:0.585, [valid] acc:0.821\n",
      "9:1960 [train] loss:0.583, [valid] acc:0.822\n",
      "9:1980 [train] loss:0.581, [valid] acc:0.824\n",
      "9:2000 [train] loss:0.578, [valid] acc:0.825\n",
      "9:2020 [train] loss:0.575, [valid] acc:0.827\n",
      "9:2040 [train] loss:0.573, [valid] acc:0.827\n",
      "9:2060 [train] loss:0.570, [valid] acc:0.828\n",
      "9:2080 [train] loss:0.568, [valid] acc:0.829\n",
      "9:2100 [train] loss:0.567, [valid] acc:0.829\n",
      "9:2120 [train] loss:0.565, [valid] acc:0.831\n",
      "9:2140 [train] loss:0.562, [valid] acc:0.831\n",
      "10:2160 [train] loss:0.560, [valid] acc:0.831\n",
      "10:2180 [train] loss:0.558, [valid] acc:0.832\n",
      "10:2200 [train] loss:0.556, [valid] acc:0.833\n",
      "10:2220 [train] loss:0.554, [valid] acc:0.833\n",
      "10:2240 [train] loss:0.552, [valid] acc:0.834\n",
      "10:2260 [train] loss:0.550, [valid] acc:0.836\n",
      "10:2280 [train] loss:0.548, [valid] acc:0.836\n",
      "10:2300 [train] loss:0.546, [valid] acc:0.837\n",
      "10:2320 [train] loss:0.545, [valid] acc:0.837\n",
      "10:2340 [train] loss:0.543, [valid] acc:0.838\n",
      "10:2360 [train] loss:0.541, [valid] acc:0.839\n",
      "11:2380 [train] loss:0.540, [valid] acc:0.839\n",
      "11:2400 [train] loss:0.538, [valid] acc:0.839\n",
      "11:2420 [train] loss:0.536, [valid] acc:0.840\n",
      "11:2440 [train] loss:0.534, [valid] acc:0.841\n",
      "11:2460 [train] loss:0.532, [valid] acc:0.841\n",
      "11:2480 [train] loss:0.531, [valid] acc:0.842\n",
      "11:2500 [train] loss:0.529, [valid] acc:0.843\n",
      "11:2520 [train] loss:0.527, [valid] acc:0.844\n",
      "11:2540 [train] loss:0.526, [valid] acc:0.844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_dl, valid_dl, test_dl \u001b[39m=\u001b[39m get_mnist_dl(batch_size_train\u001b[39m=\u001b[39mtrain_batch, batch_size_valid\u001b[39m=\u001b[39mvalid_batch, device \u001b[39m=\u001b[39m DEVICE)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m Quantized_backprop_BNN(lr \u001b[39m=\u001b[39m lr, device\u001b[39m=\u001b[39mDEVICE)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m stats \u001b[39m=\u001b[39m run_experiment(model, train_dl, valid_dl, test_dl, max_epochs\u001b[39m=\u001b[39;49mmax_epochs, device \u001b[39m=\u001b[39;49m DEVICE)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m print_stats(stats)\n",
      "\u001b[1;32m/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb Cell 17\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model, train_dl, valid_dl, test_dl, max_epochs, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m stats[\u001b[39m'\u001b[39m\u001b[39mtrain-loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend((itr, model\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m itr \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m itr \u001b[39m%\u001b[39m \u001b[39m20\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     valid_acc \u001b[39m=\u001b[39m get_acc(model, valid_dl, device \u001b[39m=\u001b[39;49m device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     stats[\u001b[39m'\u001b[39m\u001b[39mvalid-acc\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend((itr, valid_acc))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     s \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mitr\u001b[39m}\u001b[39;00m\u001b[39m [train] loss:\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, [valid] acc:\u001b[39m\u001b[39m{\u001b[39;00mvalid_acc\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb Cell 17\u001b[0m in \u001b[0;36mget_acc\u001b[0;34m(model, dl, device)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     one_hot_y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     one_hot_y[[i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])], [k\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m y]] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     model\u001b[39m.\u001b[39;49mforward(X, one_hot_y)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     acc\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39margmax(model\u001b[39m.\u001b[39moutput, dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m y)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m acc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(acc)\n",
      "\u001b[1;32m/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb Cell 17\u001b[0m in \u001b[0;36mQuantized_backprop_BNN.forward\u001b[0;34m(self, input, labels)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, labels):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(\u001b[39minput\u001b[39m, (\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc_1\u001b[39m.\u001b[39;49mforward(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mRelu_1\u001b[39m.\u001b[39mforward(output)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m    output = self.fc_2.forward(output)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m    output = self.Relu_2.forward(output)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m    output = self.fc_3.forward(output)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m    output = self.Relu_3.forward(output)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb Cell 17\u001b[0m in \u001b[0;36mQLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp_bias\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_weights) \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_bias\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703935222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/Quantizaed_neural_network/Back_propagation_base_line.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl, test_dl = get_mnist_dl(batch_size_train=train_batch, batch_size_valid=valid_batch, device = DEVICE)\n",
    "model = Quantized_backprop_BNN(lr = lr, device=DEVICE)\n",
    "stats = run_experiment(model, train_dl, valid_dl, test_dl, max_epochs=max_epochs, device = DEVICE)\n",
    "print_stats(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('test_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3740b4c8389f643b958801bf28dfaa46be3508a87b50265337019eadb57ea2b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
